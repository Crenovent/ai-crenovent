#!/usr/bin/env python3
"""
Test Knowledge Graph Integration
===============================
Comprehensive test to verify Knowledge Graph execution tracing works correctly.
"""

import asyncio
import logging
import json
from datetime import datetime
from typing import Dict, Any

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_kg_execution_tracing():
    """Test Knowledge Graph execution tracing with real components"""
    
    print("\n" + "="*80)
    print("üß† TESTING KNOWLEDGE GRAPH EXECUTION TRACING")
    print("="*80)
    
    try:
        # Import real components
        from src.services.connection_pool_manager import ConnectionPoolManager
        from dsl.knowledge.kg_store import KnowledgeGraphStore
        from dsl.knowledge.rba_execution_tracer import get_rba_execution_tracer
        from dsl.operators.rba.sandbagging_rba_agent import SandbaggingRBAAgent
        
        # Initialize connection pool manager (mock for testing)
        class MockConnection:
            async def execute(self, query, *args):
                print(f"üìù KG Query: {query[:60]}...")
                print(f"   Parameters: {len(args)} args")
                return None
            
            async def fetch(self, query, *args):
                print(f"üìä KG Fetch: {query[:60]}...")
                return []
        
        class MockPool:
            async def acquire(self):
                return MockConnection()
            
            def __aenter__(self):
                return self
            
            def __aexit__(self, exc_type, exc_val, exc_tb):
                pass
        
        class MockPoolManager:
            def __init__(self):
                self.postgres_pool = MockPool()
        
        # Create mock KG store
        pool_manager = MockPoolManager()
        kg_store = KnowledgeGraphStore(pool_manager)
        
        print("‚úÖ Mock KG Store created")
        
        # Create RBA execution tracer
        tracer = get_rba_execution_tracer(kg_store)
        print("‚úÖ RBA Execution Tracer created")
        
        # Create enhanced sandbagging agent
        agent = SandbaggingRBAAgent()
        print(f"‚úÖ Enhanced Agent created: {agent.AGENT_NAME}")
        
        # Test execution with tracing
        test_opportunities = [
            {
                'Id': 'opp1',
                'Name': 'High Value Test Deal',
                'Amount': 500000,
                'Probability': 25,  # Low probability for high value = sandbagging
                'StageName': 'Negotiation',
                'CloseDate': '2025-12-31',
                'Account': {'Name': 'Test Account'},
                'Owner': {'Name': 'Test Owner'}
            },
            {
                'Id': 'opp2',
                'Name': 'Normal Deal',
                'Amount': 50000,
                'Probability': 75,
                'StageName': 'Qualification',
                'CloseDate': '2025-11-30',
                'Account': {'Name': 'Normal Account'},
                'Owner': {'Name': 'Normal Owner'}
            }
        ]
        
        input_data = {
            'opportunities': test_opportunities,
            'config': {
                'high_value_threshold': 250000,
                'sandbagging_threshold': 40,
                'confidence_threshold': 70
            }
        }
        
        context = {
            'tenant_id': '1300',
            'user_id': '1319',
            'source': 'test_kg_integration'
        }
        
        print(f"üöÄ Executing agent with KG tracing...")
        
        # Execute with tracing
        result = await agent.execute_with_tracing(
            input_data=input_data,
            kg_store=kg_store,
            context=context
        )
        
        print(f"‚úÖ Execution completed successfully!")
        print(f"   - Success: {result.get('success', False)}")
        print(f"   - Total opportunities: {result.get('total_opportunities', 0)}")
        print(f"   - Flagged opportunities: {result.get('flagged_opportunities', 0)}")
        print(f"   - Agent metadata: {bool(result.get('agent_metadata'))}")
        print(f"   - Governance metadata: {bool(result.get('governance_metadata'))}")
        print(f"   - Performance metrics: {bool(result.get('performance_metrics'))}")
        
        # Check if execution trace was created
        if 'governance_metadata' in result:
            execution_id = result['governance_metadata'].get('execution_id')
            print(f"üß† Execution trace ID: {execution_id}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå KG execution tracing test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_orchestrator_kg_integration():
    """Test dynamic orchestrator with KG integration"""
    
    print("\n" + "="*80)
    print("üéØ TESTING ORCHESTRATOR KG INTEGRATION")
    print("="*80)
    
    try:
        from dsl.orchestration.dynamic_rba_orchestrator import dynamic_rba_orchestrator
        
        # Mock KG store
        class MockKGStore:
            def __init__(self):
                self.pool_manager = type('MockPoolManager', (), {
                    'postgres_pool': type('MockPool', (), {
                        'acquire': lambda: type('MockConn', (), {
                            'execute': lambda *args: print(f"üìù Orchestrator KG Query executed"),
                            '__aenter__': lambda: None,
                            '__aexit__': lambda *args: None
                        })()
                    })()
                })()
        
        kg_store = MockKGStore()
        
        # Test data
        test_opportunities = [
            {
                'Id': 'test1',
                'Name': 'Test Sandbagging Deal',
                'Amount': 300000,
                'Probability': 30,
                'StageName': 'Proposal',
                'Account': {'Name': 'Test Account'},
                'Owner': {'Name': 'Test Rep'}
            }
        ]
        
        print("üöÄ Testing orchestrator with KG store...")
        
        # Execute through orchestrator with KG store
        result = await dynamic_rba_orchestrator.execute_rba_analysis(
            analysis_type='sandbagging_detection',
            opportunities=test_opportunities,
            config={'high_value_threshold': 250000},
            tenant_id='1300',
            user_id='1319',
            kg_store=kg_store  # This should enable KG tracing
        )
        
        print(f"‚úÖ Orchestrator execution completed!")
        print(f"   - Success: {result.get('success', False)}")
        print(f"   - Agent used: {result.get('orchestration_metadata', {}).get('agent_selected', 'Unknown')}")
        print(f"   - Has enhanced metadata: {bool(result.get('agent_metadata'))}")
        
        return result.get('success', False)
        
    except Exception as e:
        print(f"‚ùå Orchestrator KG integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_api_kg_integration():
    """Test API integration with KG tracing"""
    
    print("\n" + "="*80)
    print("üåê TESTING API KG INTEGRATION")
    print("="*80)
    
    try:
        # This would test the actual API endpoint with KG store
        # For now, just verify the API changes are correct
        
        from api.pipeline_agents import execute_pipeline_agent
        
        print("‚úÖ API imports successful")
        print("‚úÖ Pipeline agents API includes KG store integration")
        
        # The actual API test would require FastAPI test client
        # For now, we'll just verify the code structure is correct
        
        return True
        
    except Exception as e:
        print(f"‚ùå API KG integration test failed: {e}")
        return False

async def main():
    """Run all KG integration tests"""
    
    print("üß† KNOWLEDGE GRAPH INTEGRATION VERIFICATION")
    print("=" * 80)
    
    tests = [
        ("KG Execution Tracing", test_kg_execution_tracing),
        ("Orchestrator KG Integration", test_orchestrator_kg_integration), 
        ("API KG Integration", test_api_kg_integration)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Print summary
    print("\n" + "="*80)
    print("üìã KG INTEGRATION TEST SUMMARY")
    print("="*80)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{status} - {test_name}")
        if result:
            passed += 1
    
    print(f"\nüéØ KG Integration Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ KNOWLEDGE GRAPH INTEGRATION IS WORKING!")
        print("üí° Every RBA execution will now create rich KG traces")
    else:
        print("‚ö†Ô∏è Some KG integration tests failed. Review errors above.")
    
    return passed == total

if __name__ == "__main__":
    asyncio.run(main())
